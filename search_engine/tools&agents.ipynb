{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wiki and Arxiv Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import ArxivQueryRun, WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper, ArxivAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_api_wrapper = WikipediaAPIWrapper(top_k_results = 1,doc_content_chars_max = 256)\n",
    "wiki_tool = WikipediaQueryRun(api_wrapper = wiki_api_wrapper)\n",
    "wiki_tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arxiv'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv_api_wrapper = ArxivAPIWrapper(top_k_results = 1,doc_content_chars_max = 256)\n",
    "arxiv_tool = ArxivQueryRun(api_wrapper = arxiv_api_wrapper)\n",
    "arxiv_tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [wiki_tool, arxiv_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_loader =  WebBaseLoader(web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",), \n",
    "                            bs_kwargs=dict(parse_only=bs4.SoupStrainer(class_=('post-title', 'post-content', 'post-header'))))\n",
    "doc = web_loader.load()\n",
    "chunked_doc = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 250).split_documents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "import openai\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "embedding = OpenAIEmbeddings(model = 'text-embedding-3-large',)\n",
    "vector_db = Chroma.from_documents(chunked_doc, embedding)\n",
    "retriever = vector_db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'custom_tool'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "retriever_tool = create_retriever_tool(retriever = retriever, name = 'custom_tool', description = 'this is a practise for custom tool')\n",
    "retriever_tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [retriever_tool] + tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tool(name='custom_tool', description='this is a practise for custom tool', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x710823fe00d0>, retriever=VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x7108233d0640>), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'), coroutine=functools.partial(<function _aget_relevant_documents at 0x710823fe03a0>, retriever=VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x7108233d0640>), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n')),\n",
       " WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from '/home/revlis_ai/anaconda3/envs/env_llm/lib/python3.8/site-packages/wikipedia/__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=256)),\n",
       " ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=256))]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine tools and LLMs into Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(...)\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7107fb967790>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7107fb96a910>, root_client=<openai.OpenAI object at 0x7108141baac0>, root_async_client=<openai.AsyncOpenAI object at 0x7107fb9677f0>, model_name='gpt-4o-mini', openai_api_key=SecretStr('**********'), openai_proxy=''), kwargs={'tools': [{'type': 'function', 'function': {'name': 'custom_tool', 'description': 'this is a practise for custom tool', 'parameters': {'type': 'object', 'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query']}}}, {'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'type': 'object', 'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query']}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'type': 'object', 'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query']}}}]})\n",
       "| OpenAIToolsAgentOutputParser()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import create_openai_tools_agent\n",
    "agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(...)\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7107fb967790>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7107fb96a910>, root_client=<openai.OpenAI object at 0x7108141baac0>, root_async_client=<openai.AsyncOpenAI object at 0x7107fb9677f0>, model_name='gpt-4o-mini', openai_api_key=SecretStr('**********'), openai_proxy=''), kwargs={'tools': [{'type': 'function', 'function': {'name': 'custom_tool', 'description': 'this is a practise for custom tool', 'parameters': {'type': 'object', 'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query']}}}, {'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'type': 'object', 'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query']}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'type': 'object', 'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query']}}}]})\n",
       "| OpenAIToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[Tool(name='custom_tool', description='this is a practise for custom tool', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x710823fe00d0>, retriever=VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x7108233d0640>), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'), coroutine=functools.partial(<function _aget_relevant_documents at 0x710823fe03a0>, retriever=VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x7108233d0640>), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n')), WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from '/home/revlis_ai/anaconda3/envs/env_llm/lib/python3.8/site-packages/wikipedia/__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=256)), ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=256))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose = True)\n",
    "agent_executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'Maximum Inner Product Search'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPage: Maximum inner-product search\n",
      "Summary: Maximum inner-product search (MIPS) is a search problem, with a corresponding class of search algorithms which attempt to maximise the inner product between a query and the data items to be retrieved. MIPS algori\u001b[0m\u001b[32;1m\u001b[1;3mMaximum Inner Product Search (MIPS) is a search problem that focuses on maximizing the inner product between a query and data items that need to be retrieved. The inner product is a mathematical operation that takes two equal-length sequences of numbers (often represented as vectors) and returns a single number, which represents a measure of similarity or correlation between the two sequences.\n",
      "\n",
      "MIPS has a range of applications, particularly in areas such as information retrieval, recommendation systems, and machine learning, where finding the most relevant items based on a user's query is crucial. Various algorithms have been developed to efficiently solve the MIPS problem, with the goal of quickly identifying the data items that yield the highest inner product with a given query vector.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'tell me about Maximum Inner Product Search',\n",
       " 'output': \"Maximum Inner Product Search (MIPS) is a search problem that focuses on maximizing the inner product between a query and data items that need to be retrieved. The inner product is a mathematical operation that takes two equal-length sequences of numbers (often represented as vectors) and returns a single number, which represents a measure of similarity or correlation between the two sequences.\\n\\nMIPS has a range of applications, particularly in areas such as information retrieval, recommendation systems, and machine learning, where finding the most relevant items based on a user's query is crucial. Various algorithms have been developed to efficiently solve the MIPS problem, with the goal of quickly identifying the data items that yield the highest inner product with a given query vector.\"}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({'input': 'tell me about Maximum Inner Product Search'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'Machine Learning'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPage: Machine learning\n",
      "Summary: Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalize to unseen data, and thus perform tasks without e\u001b[0m\u001b[32;1m\u001b[1;3mMachine learning (ML) is a field of study within artificial intelligence that focuses on the development and study of statistical algorithms capable of learning from data. These algorithms can generalize from the data they are trained on to make predictions or perform tasks on unseen data. Essentially, machine learning enables systems to improve their performance on a task over time without being explicitly programmed for each specific scenario.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is machine learning',\n",
       " 'output': 'Machine learning (ML) is a field of study within artificial intelligence that focuses on the development and study of statistical algorithms capable of learning from data. These algorithms can generalize from the data they are trained on to make predictions or perform tasks on unseen data. Essentially, machine learning enables systems to improve their performance on a task over time without being explicitly programmed for each specific scenario.'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({'input': 'what is machine learning'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `arxiv` with `{'query': '1706.03762'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mPublished: 2023-08-02\n",
      "Title: Attention Is All You Need\n",
      "Authors: Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin\n",
      "Summary: The dominant sequence transduction models are based on complex\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `arxiv` with `{'query': 'Attention Is All You Need'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mPublished: 2024-07-22\n",
      "Title: Attention Is All You Need But You Don't Need All Of It For Inference of Large Language Models\n",
      "Authors: Georgy Tyukin, Gbetondji J-S Dovonon, Jean Kaddour, Pasquale Minervini\n",
      "Summary: The inference demand for LLMs has skyrockete\u001b[0m\u001b[32;1m\u001b[1;3mThe paper with the identifier **1706.03762**, titled **\"Attention Is All You Need But You Don't Need All Of It For Inference of Large Language Models,\"** was published on July 22, 2024. \n",
      "\n",
      "### Summary:\n",
      "The paper addresses the increasing demand for inference in large language models (LLMs). It discusses how the inference requirements for these models have dramatically increased, and it explores the potential for optimizing the attention mechanisms used in these models to improve efficiency without sacrificing performance. \n",
      "\n",
      "If you would like more detailed information or specific aspects of the paper, feel free to ask!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is the paper 1706.03762 about',\n",
       " 'output': 'The paper with the identifier **1706.03762**, titled **\"Attention Is All You Need But You Don\\'t Need All Of It For Inference of Large Language Models,\"** was published on July 22, 2024. \\n\\n### Summary:\\nThe paper addresses the increasing demand for inference in large language models (LLMs). It discusses how the inference requirements for these models have dramatically increased, and it explores the potential for optimizing the attention mechanisms used in these models to improve efficiency without sacrificing performance. \\n\\nIf you would like more detailed information or specific aspects of the paper, feel free to ask!'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({'input': 'what is the paper 1706.03762 about'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'Chain of Hindsight'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPage: Automatic (The Jesus and Mary Chain album)\n",
      "Summary: Automatic is the third studio album by Scottish alternative rock band the Jesus and Mary Chain, released on 9 October 1989 by Blanco y Negro Records. The group on this record consists of the core du\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `custom_tool` with `{'query': 'Chain of Hindsight'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mChain of Hindsight (CoH; Liu et al. 2023) encourages the model to improve on its own outputs by explicitly presenting it with a sequence of past outputs, each annotated with feedback. Human feedback data is a collection of $D_h = \\{(x, y_i , r_i , z_i)\\}_{i=1}^n$, where $x$ is the prompt, each $y_i$ is a model completion, $r_i$ is the human rating of $y_i$, and $z_i$ is the corresponding human-provided hindsight feedback. Assume the feedback tuples are ranked by reward, $r_n \\geq r_{n-1} \\geq \\dots \\geq r_1$ The process is supervised fine-tuning where the data is a sequence in the form of $\\tau_h = (x, z_i, y_i, z_j, y_j, \\dots, z_n, y_n)$, where $\\leq i \\leq j \\leq n$. The model is finetuned to only predict $y_n$ where conditioned on the sequence prefix, such that the model can self-reflect to produce better output based on the feedback sequence. The model can optionally receive multiple rounds of instructions with human annotators at test time.\n",
      "\n",
      "Fig. 3. Illustration of the Reflexion framework. (Image source: Shinn & Labash, 2023)\n",
      "The heuristic function determines when the trajectory is inefficient or contains hallucination and should be stopped. Inefficient planning refers to trajectories that take too long without success. Hallucination is defined as encountering a sequence of consecutive identical actions that lead to the same observation in the environment.\n",
      "Self-reflection is created by showing two-shot examples to LLM and each example is a pair of (failed trajectory, ideal reflection for guiding future changes in the plan). Then reflections are added into the agent’s working memory, up to three, to be used as context for querying LLM.\n",
      "\n",
      "Fig. 5. After fine-tuning with CoH, the model can follow instructions to produce outputs with incremental improvement in a sequence. (Image source: Liu et al. 2023)\n",
      "The idea of CoH is to present a history of sequentially improved outputs  in context and train the model to take on the trend to produce better outputs. Algorithm Distillation (AD; Laskin et al. 2023) applies the same idea to cross-episode trajectories in reinforcement learning tasks, where an algorithm is encapsulated in a long history-conditioned policy. Considering that an agent interacts with the environment many times and in each episode the agent gets a little better, AD concatenates this learning history and feeds that into the model. Hence we should expect the next predicted action to lead to better performance than previous trials. The goal is to learn the process of RL instead of training a task-specific policy itself.\n",
      "\n",
      "Reflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\n",
      "\n",
      "Prompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\n",
      "\n",
      "\n",
      "Planning & Reacting: translate the reflections and the environment information into actions\n",
      "\n",
      "Planning is essentially in order to optimize believability at the moment vs in time.\n",
      "Prompt template: {Intro of an agent X}. Here is X's plan today in broad strokes: 1)\n",
      "Relationships between agents and observations of one agent by another are all taken into consideration for planning and reacting.\n",
      "Environment information is present in a tree structure.\u001b[0m\u001b[32;1m\u001b[1;3mThe \"Chain of Hindsight\" (CoH) is a method developed by Liu et al. in 2023 that aims to enhance the performance of models by utilizing a sequence of past outputs along with feedback. Here are the key points about this approach:\n",
      "\n",
      "1. **Feedback Data Structure**: CoH utilizes human feedback data structured as tuples that include a prompt, model completions, human ratings of those completions, and corresponding hindsight feedback. This feedback is ranked by reward, allowing the model to learn from its past outputs.\n",
      "\n",
      "2. **Supervised Fine-tuning**: The fine-tuning process involves presenting the model with a sequence that helps it reflect on previous outputs to generate improved future outputs. The format of the data used for training includes multiple outputs and their feedback, enabling the model to self-reflect and enhance its responses.\n",
      "\n",
      "3. **Inefficiency and Hallucination Detection**: CoH incorporates a heuristic function to identify when a model's trajectory is inefficient or experiencing hallucinations—defined as producing the same output repeatedly without progressing towards a solution.\n",
      "\n",
      "4. **Self-reflection Mechanism**: The method involves showing two-shot examples of failed trajectories and ideal reflections, which are used to guide the model's future actions. This allows the model to synthesize memories and generate higher-level inferences over time.\n",
      "\n",
      "5. **Application in Reinforcement Learning**: The concept is also applied in reinforcement learning through Algorithm Distillation (AD), which encapsulates a long history of agent interactions with the environment to improve future actions.\n",
      "\n",
      "6. **Planning and Reacting**: CoH emphasizes the importance of planning actions based on past observations and reflections to optimize performance, taking into account the relationships between agents and their observations.\n",
      "\n",
      "Overall, the Chain of Hindsight is an innovative approach that encourages models to learn from their previous experiences and feedback, leading to progressively better performance.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'tell me about Chain of Hindsight',\n",
       " 'output': 'The \"Chain of Hindsight\" (CoH) is a method developed by Liu et al. in 2023 that aims to enhance the performance of models by utilizing a sequence of past outputs along with feedback. Here are the key points about this approach:\\n\\n1. **Feedback Data Structure**: CoH utilizes human feedback data structured as tuples that include a prompt, model completions, human ratings of those completions, and corresponding hindsight feedback. This feedback is ranked by reward, allowing the model to learn from its past outputs.\\n\\n2. **Supervised Fine-tuning**: The fine-tuning process involves presenting the model with a sequence that helps it reflect on previous outputs to generate improved future outputs. The format of the data used for training includes multiple outputs and their feedback, enabling the model to self-reflect and enhance its responses.\\n\\n3. **Inefficiency and Hallucination Detection**: CoH incorporates a heuristic function to identify when a model\\'s trajectory is inefficient or experiencing hallucinations—defined as producing the same output repeatedly without progressing towards a solution.\\n\\n4. **Self-reflection Mechanism**: The method involves showing two-shot examples of failed trajectories and ideal reflections, which are used to guide the model\\'s future actions. This allows the model to synthesize memories and generate higher-level inferences over time.\\n\\n5. **Application in Reinforcement Learning**: The concept is also applied in reinforcement learning through Algorithm Distillation (AD), which encapsulates a long history of agent interactions with the environment to improve future actions.\\n\\n6. **Planning and Reacting**: CoH emphasizes the importance of planning actions based on past observations and reflections to optimize performance, taking into account the relationships between agents and their observations.\\n\\nOverall, the Chain of Hindsight is an innovative approach that encourages models to learn from their previous experiences and feedback, leading to progressively better performance.'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({'input': 'tell me about Chain of Hindsight'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'self-reflection'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPage: Self-reflection\n",
      "Summary: Self-reflection is the ability to witness and evaluate one's own cognitive, emotional, and behavioural processes. In psychology, other terms used for this self-observation include 'reflective awareness', and 'reflective consc\u001b[0m\u001b[32;1m\u001b[1;3mSelf-reflection is the ability to witness and evaluate one's own cognitive, emotional, and behavioral processes. In psychology, it is also referred to as \"reflective awareness\" or \"reflective consciousness.\" This practice involves introspection and the examination of one's thoughts, feelings, and actions, allowing individuals to gain insight into their motivations and behaviors. Self-reflection can lead to personal growth, improved decision-making, and a deeper understanding of oneself.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'tell me about self-reflection',\n",
       " 'output': 'Self-reflection is the ability to witness and evaluate one\\'s own cognitive, emotional, and behavioral processes. In psychology, it is also referred to as \"reflective awareness\" or \"reflective consciousness.\" This practice involves introspection and the examination of one\\'s thoughts, feelings, and actions, allowing individuals to gain insight into their motivations and behaviors. Self-reflection can lead to personal growth, improved decision-making, and a deeper understanding of oneself.'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({'input': 'tell me about self-reflection'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_llm",
   "language": "python",
   "name": "env_llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
